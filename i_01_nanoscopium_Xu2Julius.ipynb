{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Created Date: 2021-11-20 14:56:35\n",
    "Author: Xu LIU\n",
    "Email: jasonlx1993@gmail.com\n",
    "Last Modified: Sat Nov 20 2021\n",
    "----------------------------------------------------------------------\n",
    "Copyright (c) 2021 DONG\n",
    "----------------------------------------------------------------------\n",
    "'''\n",
    "import numpy as np\n",
    "import os,shutil\n",
    "from pynx.utils import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import medfilt2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir_data,extension=None,keys=None,fulldepth=False):\n",
    "    '''\n",
    "    return a list of path of all files satisfying \n",
    "    extention and keys in dir_data, if keys are not specified, \n",
    "    all files will be returned.\n",
    "\n",
    "    dir_data: directory of the data\n",
    "    extension:string like '.txt', not sensitive to case.\n",
    "    keys: string 'Keys', not sensitive to case.\n",
    "    '''\n",
    "    if extension is not None:\n",
    "        extension = extension.lower()\n",
    "    if keys is not None:\n",
    "        keys = keys.lower()\n",
    "    lst_path = list()\n",
    "    if os.path.exists(dir_data):\n",
    "        if not fulldepth:\n",
    "            for filename in os.listdir(dir_data):\n",
    "                filename=filename.lower()\n",
    "                if extension is not None:\n",
    "                    if filename.endswith(extension):\n",
    "                        if keys is not None:\n",
    "                            if keys in filename:\n",
    "                                lst_path.append(os.path.join(dir_data,filename))\n",
    "                        else:lst_path.append(os.path.join(dir_data,filename))\n",
    "                elif keys is not None:\n",
    "                    if keys in filename:\n",
    "                        lst_path.append(os.path.join(dir_data,filename))\n",
    "                elif os.path.isfile(filename):\n",
    "                    lst_path.append(os.path.join(dir_data,filename))\n",
    "            return lst_path\n",
    "        else:\n",
    "            for root,dir,file in os.walk(dir_data):\n",
    "                if file:\n",
    "                    for filei in file:\n",
    "                        if extension is not None:\n",
    "                            if filei.endswith(extension):\n",
    "                                if keys is not None:\n",
    "                                    if keys in filei:\n",
    "                                        lst_path.append(os.path.join(root,filei))\n",
    "                                else:lst_path.append(os.path.join(root,filei))\n",
    "                        elif keys is not None:\n",
    "                            if keys in filei:\n",
    "                                lst_path.append(os.path.join(root,filei))\n",
    "                        else:\n",
    "                            lst_path.append(os.path.join(root,filei))\n",
    "            return lst_path\n",
    "    else:\n",
    "        print(f'{dir_data} not found.')\n",
    "        return None\n",
    "\n",
    "def make_dirs(dir_data,dir_name=None,list_ssubdir_names=None):\n",
    "    '''\n",
    "    the structure of this function:\n",
    "        dir_data\\\\dir_result\\\\subsubdirs\n",
    "        dict_ssubdirs: dir_result + subsubdirs\n",
    "\n",
    "    dir_data: the dir path where contains the data needs to be analyzed.\n",
    "    dir_name: this sub folder dir_result which is named 'result_YYMMDDHHMM', \n",
    "                an str can be attached at the end if 'dir_name' is given. \n",
    "                If creating same files within 1 minutes, the former one will\n",
    "                be overwritten.\n",
    "    list_ssubdir_names: a customized list of string which dontes the subsub directory,\n",
    "                        where maybe you want to save some thing.\n",
    "    ch_workingdir: by default, the working dir will be switched to the subsub dir('0_dir_working'),\n",
    "    so that some results from other scripts can be automatically saved in subsub dir('0_dir_working'),\n",
    "    if False, one may need to check the working dir, before saving.\n",
    "\n",
    "    return:\n",
    "        dict_ssubdirs: the absolute pathes of the sub directory and subsub directories,\n",
    "    result folder can be accessed by dict_ssubdirs['result'], others can be accessed by\n",
    "    the keys given by you.\n",
    "    '''\n",
    "    current_time = time.strftime(\"%Y%m%d%H%M\",time.localtime())\n",
    "    # sub dir, result folder\n",
    "    dir_result = dir_data+ '\\\\' + current_time\n",
    "    if dir_name is not None:\n",
    "        dir_result = dir_result + '_' + str(dir_name)\n",
    "    # list_ssubdir, customized sub sub folders\n",
    "    if (list_ssubdir_names is not None) and len(list_ssubdir_names)!=0:\n",
    "        dict_dirs = dict.fromkeys(list_ssubdir_names, 0)\n",
    "        for key in dict_dirs.keys():\n",
    "            dict_dirs[key] = dir_result + '\\\\' + key\n",
    "        dict_dirs['result'] = dir_result\n",
    "    else:\n",
    "        dict_dirs = {'result':dir_result}\n",
    "    if os.path.exists(dir_result):\n",
    "        print('subsub dirs result existed, clearing...')\n",
    "        for filename in os.listdir(dir_result):\n",
    "            file_path = os.path.join(dir_result, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)\n",
    "            except Exception as eor:\n",
    "                print('failed to delete %s. Reason: %s' % (file_path, eor))\n",
    "        print('regenerating...')\n",
    "        for key in dict_dirs.keys():\n",
    "            if key=='result':\n",
    "                continue\n",
    "            os.mkdir(dict_dirs[key])\n",
    "    else:\n",
    "        print('creating dirs in the data file...')\n",
    "        os.mkdir(dir_result)\n",
    "        for key in dict_dirs.keys():\n",
    "            if key=='result': \n",
    "                continue\n",
    "            os.mkdir(dict_dirs[key])\n",
    "    os.chdir(dir_result)\n",
    "    print('dirs are made successfully.')\n",
    "    return dict_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "post processing part, should be separated to a py files if needed.\n",
    "hot pixels of 171*512*512 data will be replaced by 0 and apply a meidan filter with kernel size defined below. And a spectrum for each position(36 in total) will be saved as npy file. \n",
    "'''\n",
    "\n",
    "# get files\n",
    "dir_data = r'E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02'\n",
    "lstf_nxs = get_files(dir_data,extension=\".nxs\")\n",
    "\n",
    "# get mask valide values are 1\n",
    "lstf_mask = get_files(dir_data,extension='.npz',keys=\"mask\")\n",
    "file_npz = np.load(lstf_mask[0]).items()\n",
    "for v in file_npz:\n",
    "    mask_raw = v[1]\n",
    "    break\n",
    "mask_raw[255,:] = 0\n",
    "mask_raw[:,255] = 0\n",
    "mask_raw[260,:] = 0\n",
    "mask_raw[:,260] = 0\n",
    "mask_raw = np.where((mask_raw==0)|(mask_raw==1), mask_raw^1, mask_raw)\n",
    "\n",
    "# make mask of removing bad pixels\n",
    "mask_nocrs = np.copy(mask_raw)\n",
    "mask_nocrs = np.delete(mask_nocrs, np.s_[256:260],axis=0)\n",
    "mask_nocrs = np.delete(mask_nocrs, np.s_[256:260],axis=1)\n",
    "# remove reflection for KB\n",
    "left,top,right,bottom = 75,275,85,240\n",
    "mask_nocrs[bottom:top+1,left:right+1] = 0\n",
    "\n",
    "# make dirs\n",
    "kernelsize = 1\n",
    "lst_dirs = make_dirs(dir_data,dir_name=f\"Post_MaskedPxlKB_medsize{kernelsize}\")\n",
    "\n",
    "# get hdf5 files\n",
    "lstf_name = []\n",
    "lstf_hdf = []\n",
    "lst_entry = []\n",
    "lst_pos = []\n",
    "ary3_sum = np.zeros((len(lstf_nxs),36))\n",
    "\n",
    "# remove hotpxl and generate new nxs files\n",
    "for idx_nxs,nxsi in enumerate(lstf_nxs):\n",
    "    # get file name\n",
    "    fnamei = os.path.split(os.path.splitext(nxsi)[0])[-1] + \".nxs\"\n",
    "    lstf_name.append(fnamei)\n",
    "    # get hdf5 files\n",
    "    h5i = h5py.File(nxsi,\"r\")\n",
    "    lstf_hdf.append(h5i)\n",
    "    # get entries\n",
    "    entryi = [v for v in h5i.values()][0]\n",
    "    lst_entry.append(entryi)\n",
    "    # get 3Dimage\n",
    "    im4drawi = entryi['scan_data/Image_merlin_image']\n",
    "    nb_total = im4drawi.shape[0]*im4drawi.shape[1]\n",
    "    list_img_nb = np.arange(nb_total, dtype=np.int8)\n",
    "    if len(im4drawi.shape) == 4:\n",
    "        im3drawi = np.empty((nb_total, im4drawi.shape[-2], im4drawi.shape[-1]))\n",
    "        # flyscan data is 2D.\n",
    "        n1, n2 = im4drawi.shape[:2]\n",
    "        for i in range(n1):\n",
    "            i0 = n2 * i\n",
    "            idx_3dim = np.where(np.logical_and(list_img_nb >= i0, list_img_nb < (i0 + n2)))[0]\n",
    "            if len(idx_3dim):\n",
    "                im3drawi[idx_3dim] = im4drawi[i, list_img_nb[idx_3dim] - i0]\n",
    "    else:\n",
    "        im3drawi = im4drawi[list_img_nb]\n",
    "    # remove hot pixels\n",
    "    im3drmhpxli = []\n",
    "    for idx_3dim,im2drawi in enumerate(im3drawi):\n",
    "        # get rid off bad pixels\n",
    "        im2dmaskedi = im2drawi*mask_nocrs\n",
    "        # remove hotpixels with kernel size of 3\n",
    "        im2dnewi = medfilt2d(im2dmaskedi, kernel_size=kernelsize)\n",
    "        im2dnewi[371,2] = 0\n",
    "        im2dnewi[484,222] = 0\n",
    "        im3drmhpxli.append(im2dnewi)\n",
    "        ary3_sum[idx_nxs,idx_3dim]=im2dnewi.sum()\n",
    "\n",
    "    # copy nxs and rename it\n",
    "    if os.path.exists(fnamei):\n",
    "        os.remove(fnamei)\n",
    "    shutil.copy(nxsi, fnamei)\n",
    "    h5i.close()\n",
    "    # get new hdf5 files\n",
    "    h5ri = h5py.File(fnamei,\"r+\")\n",
    "    # get new entries\n",
    "    entryri = [v for v in h5ri.values()][0]\n",
    "    # replace image data in new .nxs file\n",
    "    del entryri['scan_data/Image_merlin_image']\n",
    "    entryri['scan_data/Image_merlin_image'] = np.asarray(im3drmhpxli,dtype=np.float32)\n",
    "    h5ri.close()\n",
    "\n",
    "# save spectrum\n",
    "np.save(\"2DspectrumI.npy\",ary3_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"after post processing this part will generate broad band diffraction pattern, if needed separate this part as a py file. Note that the cross is not token into consideration yet.\"\"\"\n",
    "\n",
    "# get files\n",
    "dir_data = r'E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\\202111031714_Post_MaskedPxlKB_medsize1'\n",
    "lstf_nxs = get_files(dir_data,keys=\"flyscan\")\n",
    "\n",
    "# make dirs\n",
    "lst_dirs = make_dirs(dir_data,dir_name=\"sumDirect\")\n",
    "\n",
    "# ary3dsum\n",
    "ary3dsum = np.zeros((36,512,512))\n",
    "# start sum\n",
    "for idx_scan in range(36):\n",
    "    for nxsi in lstf_nxs:\n",
    "        # get file name\n",
    "        fnamei = os.path.split(os.path.splitext(nxsi)[0])[-1]\n",
    "        # get hdf5 files\n",
    "        h5i = h5py.File(nxsi,\"r\")\n",
    "        # get entries\n",
    "        entryi = [v for v in h5i.values()][0]\n",
    "        # get 3Dimage\n",
    "        im3drawi = entryi['scan_data/Image_merlin_image']\n",
    "        ary3dsum[idx_scan] = ary3dsum[idx_scan]+im3drawi[idx_scan]\n",
    "        h5i.close()\n",
    "    # averaging\n",
    "    ary3dsum[idx_scan] = ary3dsum[idx_scan]/len(lstf_nxs)\n",
    "\n",
    "# save file\n",
    "filename = os.path.split(os.path.splitext(lstf_nxs[0])[0])[-1] + \".nxs\"\n",
    "if os.path.exists(filename):\n",
    "    os.remove(filename)\n",
    "shutil.copy(lstf_nxs[0], filename)\n",
    "# get new hdf5 files\n",
    "h5tmp = h5py.File(filename,\"r+\")\n",
    "# get new entries\n",
    "entrytmp = [v for v in h5tmp.values()][0]\n",
    "# replace image data in new .nxs file\n",
    "del entrytmp['scan_data/Image_merlin_image']\n",
    "entrytmp['scan_data/Image_merlin_image'] = np.asarray(ary3dsum,dtype=np.float32)\n",
    "h5tmp.close()\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this part is used to add across to the broad band diffraction images, if needed separate this part as a py file.\n",
    "\"\"\"\n",
    "# get the old treated broadband file\n",
    "dir_data = r'E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\\202111031714_patch3_rm2pxl\\202111031756_sumDirect'\n",
    "path_nxs = get_files(dir_data,extension=\".nxs\")[0]\n",
    "\n",
    "# read 3dimage\n",
    "h5_tmp = h5py.File(path_nxs,\"r\")\n",
    "entry_tmp = [v for v in h5_tmp.values()][0]\n",
    "ary3d_imbdold = np.copy(entry_tmp['scan_data/Image_merlin_image'])\n",
    "h5_tmp.close()\n",
    "\n",
    "# add cross\n",
    "n = ary3d_imbdold.shape[0]\n",
    "ary3d_imbdnew = np.zeros((n, 516, 516))\n",
    "ary3d_imbdnew[:, :256, :256] = ary3d_imbdold[:, :256, :256]\n",
    "ary3d_imbdnew[:, 260:, :256] = ary3d_imbdold[:, 256:, :256]\n",
    "ary3d_imbdnew[:, :256, 260:] = ary3d_imbdold[:, :256, 256:]\n",
    "ary3d_imbdnew[:, 260:, 260:] = ary3d_imbdold[:, 256:, 256:]\n",
    "\n",
    "# creat directory to save and copy a\n",
    "lst_dirs = make_dirs(dir_data,dir_name=f\"BDwithCross\")\n",
    "\n",
    "# save data in nxs\n",
    "fnamei = \"ary3d_bdcross.nxs\"\n",
    "shutil.copy(path_nxs, fnamei)\n",
    "# get new nxs files\n",
    "h5_tmp = h5py.File(fnamei,\"r+\")\n",
    "entry_tmp = [v for v in h5_tmp.values()][0]\n",
    "# replace image data in new .nxs file\n",
    "del entry_tmp['scan_data/Image_merlin_image']\n",
    "entry_tmp['scan_data/Image_merlin_image'] = np.asarray(ary3d_imbdnew,dtype=np.float16)\n",
    "h5_tmp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part is used to monochromatize a broad band data set, accroding to their spectrum.\n",
    "\n",
    "make the import of monochro script like this:\n",
    "import monochromatization.monochromatization_of_diffraction_pattern as mono\n",
    "to ensure the functionality of the following function.\n",
    "\"\"\"\n",
    "\n",
    "def make_2Dmono(bdimage,matrix_C,scannb=None,kmax=12,show=False,saveto=None):\n",
    "    '''\n",
    "    return: a 3D array of monochromatized images in the order of increasing k value.\n",
    "    '''\n",
    "    nb_pixels = int(bdimage.shape[0]/2)\n",
    "    B_ravel = mono.cut_rotate_ravel(bdimage)\n",
    "    mk_ravel = mono.CGLS_sparse(matrix_C,B_ravel,k_max=kmax)\n",
    "    mk_3D = np.zeros((kmax,2*nb_pixels,2*nb_pixels))\n",
    "    for k_i in range(kmax):\n",
    "        mk_3D[k_i,:,:] = mono.inverse_ravel_rotate_cut(mk_ravel[:,k_i])\n",
    "    if show or saveto is not None:\n",
    "        nb_fig = kmax//4\n",
    "        if nb_fig == 0:\n",
    "            nb_fig = 1\n",
    "        elif kmax%4 != 0:\n",
    "            nb_fig+=1\n",
    "        lst_fig = [list() for i in range(nb_fig)]\n",
    "        for i in range(nb_fig):\n",
    "            lst_fig[i] = plt.figure(figsize=(18,18),tight_layout=True,dpi=100)\n",
    "            if scannb is not None:\n",
    "                lst_fig[i].suptitle(f'at scan:{scannb}')\n",
    "            lst_ax = [list() for i in range(4)]\n",
    "            for j in range(4):\n",
    "                lst_ax[j] = lst_fig[i].add_subplot(2,2,j+1)\n",
    "                current_k = i*4+j\n",
    "                if current_k<kmax:\n",
    "                    lst_ax[j].set_title(f'k={current_k+1}')\n",
    "                    lst_ax[j].imshow(mk_3D[current_k,:,:],norm=colors.LogNorm(),interpolation=\"none\")\n",
    "                else:\n",
    "                    break\n",
    "            if saveto is not None:\n",
    "                if scannb is not None:\n",
    "                    path_tmp = saveto + f'\\\\scan_{scannb}-'+f'fig_{i}.png'\n",
    "                else:\n",
    "                    path_tmp = saveto + f'fig_{i}.png'\n",
    "                lst_fig[i].savefig(path_tmp)\n",
    "            if show:\n",
    "                plt.pause(0.2)\n",
    "            if show or saveto is not None:\n",
    "                plt.close(lst_fig[i])\n",
    "    return mk_3D\n",
    "\n",
    "# change working dir\n",
    "dir_data = r'E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\\202111031714_patch3_rm2pxl\\202111031756_sumDirect\\202111191314_BDwithCross'\n",
    "\n",
    "# make directories\n",
    "lst_ssubdir_names = ['monoIMAGE']\n",
    "dict_dirs = make_dirs(dir_data,dir_name=f'mono',list_ssubdir_names=lst_ssubdir_names)\n",
    "dir_monoim = dict_dirs['monoIMAGE']\n",
    "\n",
    "# get spectrum\n",
    "path_2Dspectrum = r\"E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\\202111031714_patch3_rm2pxl\\2DspectrumI.npy\"\n",
    "ary2D_spectrum = np.load(path_2Dspectrum)\n",
    "\n",
    "# get nxs file\n",
    "path_nxs = get_files(dir_data,extension=\"nxs\")[0]\n",
    "h5tmp = h5py.File(path_nxs,\"r\")\n",
    "entrytmp = [v for v in h5tmp.values()][0]\n",
    "ary3D_bdim = np.copy(entrytmp['scan_data/Image_merlin_image'])\n",
    "h5tmp.close()\n",
    "\n",
    "# monochromatiser les images 1 par l'autre selon leurs spectres\n",
    "kmax = 8\n",
    "nb_pixels = int(ary3D_bdim.shape[1]/2)\n",
    "# get lambda\n",
    "range_energy = [8,8.68] #KeV\n",
    "engnb = ary2D_spectrum.shape[0]\n",
    "ary1d_energy = np.linspace(range_energy[0],range_energy[1],engnb)\n",
    "ary1d_lambda = 1.23984/ary1d_energy # nm\n",
    "ary4d_mono = np.zeros((kmax,36,ary3D_bdim.shape[1],ary3D_bdim.shape[2]))\n",
    "for scanidx in range(ary2D_spectrum.shape[1]):\n",
    "    print(f\"monochromatizing scan: {scanidx+1}...\")\n",
    "    # make normalised spectrum\n",
    "    ary1d_I = ary2D_spectrum[:,scanidx]\n",
    "    ary1d_I = ary1d_I-ary1d_I.min()\n",
    "    ary1d_I = ary1d_I/ary1d_I.max()\n",
    "    # calculate center wavelength\n",
    "    ary1D_Iperc = ary1d_I/ary1d_I.sum()\n",
    "    lambda_c = (ary1d_lambda*ary1D_Iperc).sum()\n",
    "    with open(\"lambdaC.txt\", \"a\") as text_file:\n",
    "        text_file.write(str(lambda_c) + \"\\n\")\n",
    "    ary1D_lambdaperc = ary1d_lambda/lambda_c\n",
    "    # build matrix C\n",
    "    matrixC = mono.build_C(ary1D_Iperc,ary1D_lambdaperc,\n",
    "                        nb_pixels,n_jobs=-2,\n",
    "                        verbose=10,Cmode='analysis')\n",
    "    # make mono for 1 scan position\n",
    "    ary4d_mono[:,scanidx,:,:] = make_2Dmono(ary3D_bdim[scanidx],matrixC,scannb=scanidx+1,kmax=kmax,show=False,saveto=dir_monoim)\n",
    "\n",
    "# save by k\n",
    "for idx,ary3dmonoi in enumerate(ary4d_mono):\n",
    "    filename = f\"k{idx+1}.nxs\"\n",
    "    shutil.copy(path_nxs, filename)\n",
    "    h5tmp = h5py.File(filename,\"r+\")\n",
    "    entrytmp = [v for v in h5tmp.values()][0]\n",
    "    del entrytmp['scan_data/Image_merlin_image']\n",
    "    entrytmp['scan_data/Image_merlin_image'] = ary3dmonoi\n",
    "    h5tmp.close()\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This part is the ptychographic reconstruction, u need PYNX newest version 2021May and a GPU to run it.\n",
    "\"\"\"\n",
    "\n",
    "from pynx.ptycho.runner.nanoscopium import PtychoRunnerNanoscopium, PtychoRunnerScanNanoscopium, \\\n",
    "    params\n",
    "\n",
    "# get files\n",
    "dir_mono = r\"E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\\202111031714_patch3_rm2pxl\\202111031756_sumDirect\\202111191314_BDwithCross\\202111191317_mono\\202111191356_BDwithoutCross\"\n",
    "dir_lambda = r\"E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\\202111031714_patch3_rm2pxl\\202111031756_sumDirect\\202111191314_BDwithCross\\202111191317_mono\"\n",
    "dir_mask = r\"E:\\PhD\\Experiment\\20210723_Soleil_Julius\\data_4_diffenergy_02\"\n",
    "path_mask = dir_mask + \"\\\\mask.npz\"\n",
    "path_lambda = dir_lambda + \"\\\\lambdaC.txt\"\n",
    "\n",
    "# get path for pynx\n",
    "ary1D_lambdaC = np.loadtxt(path_lambda)\n",
    "lambdaC = np.mean(ary1D_lambdaC)\n",
    "energyC = 1.23984/lambdaC # KeV\n",
    "pynx_nrj = 'nrj='+str(energyC)\n",
    "\n",
    "# change dir \n",
    "dict_dirs = make_dirs(dir_data=dir_mono,dir_name=f\"Recon1to8_EnergyC{energyC:.3f}_100ite\")\n",
    "\n",
    "# get path for pynx\n",
    "path_broadnxs_new = dir_mono + \"\\\\k%d.nxs\"\n",
    "pathpynx_data = 'data='+path_broadnxs_new\n",
    "pathpynx_mask = 'mask='+path_mask\n",
    "lstpynx_scan = 'scan='\n",
    "lst_k = [1,2,3,4,5,6,7,8]\n",
    "for ki in lst_k:\n",
    "    if ki == lst_k[-1]:\n",
    "        lstpynx_scan = lstpynx_scan + str(ki)\n",
    "    else:\n",
    "        lstpynx_scan = lstpynx_scan + str(ki) + ','\n",
    "\n",
    "# ptychography reconstruction\n",
    "argv = {\n",
    "        pathpynx_data,\n",
    "        lstpynx_scan,\n",
    "\n",
    "        pathpynx_mask,\n",
    "\n",
    "        'probe=focus,240e-6x240e-6,0.23',\n",
    "        'defocus=2e-3',\n",
    "        'detectordistance=2.5',\n",
    "        pynx_nrj,\n",
    "\n",
    "        'algorithm=analysis,ML**100,AP**200,pos_threshold=0.3,position=1,probe_inertia=0.01,obj_inertia=0.1,nbprobe=3,object=1,probe=1',\n",
    "        'xy=-x,y',\n",
    "\n",
    "        'verbose=5',\n",
    "        'center_probe_n=5', \n",
    "        'center_probe_max_shift=5',\n",
    "\n",
    "        'saveplot=object_phase',\n",
    "        }\n",
    "\n",
    "w = PtychoRunnerNanoscopium(argv, params, PtychoRunnerScanNanoscopium)\n",
    "w.process_scans()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
